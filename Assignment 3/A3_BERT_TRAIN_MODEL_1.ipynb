{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TZZGy6TMMOx0",
        "outputId": "cb035c42-3718-4e87-fe01-7cbd9d359f15"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tokenizers\n",
            "  Downloading tokenizers-0.13.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m37.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tokenizers\n",
            "Successfully installed tokenizers-0.13.3\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (4.65.0)\n",
            "Collecting boto3\n",
            "  Downloading boto3-1.26.111-py3-none-any.whl (135 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.6/135.6 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (2.27.1)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.9/dist-packages (2022.10.31)\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.98-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sacremoses\n",
            "  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m880.6/880.6 kB\u001b[0m \u001b[31m26.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting botocore<1.30.0,>=1.29.111\n",
            "  Downloading botocore-1.29.111-py3-none-any.whl (10.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.6/10.6 MB\u001b[0m \u001b[31m37.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Collecting s3transfer<0.7.0,>=0.6.0\n",
            "  Downloading s3transfer-0.6.0-py3-none-any.whl (79 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.6/79.6 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests) (1.26.15)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.9/dist-packages (from sacremoses) (1.16.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.9/dist-packages (from sacremoses) (8.1.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.9/dist-packages (from sacremoses) (1.2.0)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.9/dist-packages (from botocore<1.30.0,>=1.29.111->boto3) (2.8.2)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895259 sha256=a73f9e57b428ac5dd89a1614b347a9e657d52f6ad2b22c1d05af7b2ea89d3df5\n",
            "  Stored in directory: /root/.cache/pip/wheels/12/1c/3d/46cf06718d63a32ff798a89594b61e7f345ab6b36d909ce033\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sentencepiece, sacremoses, jmespath, botocore, s3transfer, boto3\n",
            "Successfully installed boto3-1.26.111 botocore-1.29.111 jmespath-1.0.1 s3transfer-0.6.0 sacremoses-0.0.53 sentencepiece-0.1.98\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.9/dist-packages (0.1.98)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.27.4-py3-none-any.whl (6.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m47.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (23.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers) (3.11.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers) (2.27.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (0.13.3)\n",
            "Collecting huggingface-hub<1.0,>=0.11.0\n",
            "  Downloading huggingface_hub-0.13.4-py3-none-any.whl (200 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.1/200.1 kB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (1.26.15)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Installing collected packages: huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.13.4 transformers-4.27.4\n"
          ]
        }
      ],
      "source": [
        "!pip install tokenizers\n",
        "!pip install tqdm boto3 requests regex sentencepiece sacremoses\n",
        "!pip install sentencepiece\n",
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tkeQn3dBMGt0"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.compose import make_column_transformer\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from google.colab import drive\n",
        "import random\n",
        "from sklearn.metrics import mean_squared_error, confusion_matrix, accuracy_score\n",
        "import time\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "import os\n",
        "import re\n",
        "import torch\n",
        "# Load pre-trained BERT model and tokenizer\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import time"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Code to load the data"
      ],
      "metadata": {
        "id": "Nl6WsZ7UzBHq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_QXqEOmgNBjl",
        "outputId": "07399077-0c36-41d2-d51b-20d2f5bbf477"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AaApWGvgM5HK"
      },
      "outputs": [],
      "source": [
        "# Temporary load data meachanism since the normal way takes way too long\n",
        "\n",
        "raw_train_data, raw_test_data = pd.read_csv(\"/content/drive/MyDrive/COMP_551/A3/aclImdb/train_data.csv\").drop('Unnamed: 0', axis=1), pd.read_csv(\"/content/drive/MyDrive/COMP_551/A3/aclImdb/test_data.csv\").drop('Unnamed: 0', axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "er7Xi4OT-VVd"
      },
      "outputs": [],
      "source": [
        "raw_train_data = raw_train_data.iloc[:2500, :] # Artificially reducing the training data size here\n",
        "raw_test_data = raw_test_data.iloc[:200, :] # Artificially reducing the test data size here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h3cSpsXvOd2k"
      },
      "outputs": [],
      "source": [
        "# preprocessing\n",
        "\n",
        "def preprocess_text(text):\n",
        "    # Lowercase the text\n",
        "    text = text.lower()\n",
        "\n",
        "    # Remove special characters and punctuation\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)\n",
        "\n",
        "    # Remove extra whitespace\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "\n",
        "    return text\n",
        "\n",
        "raw_train_data['text'] = raw_train_data['text'].apply(preprocess_text)\n",
        "raw_test_data['text'] = raw_test_data['text'].apply(preprocess_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113,
          "referenced_widgets": [
            "1235840e2ed447929e9b1fede396525a",
            "fdc0b659cc734572bf383114b687beff",
            "97331fa7721445e695708015e5f54ae8",
            "f5bbe87411cd4ac4a84d24e757cb08f0",
            "fc8a95296f4943bd8d4e3baaf1db8792",
            "5d1583ac44de4024bc64d90329300a03",
            "5ddcf8fa3ca24fcb84e4156aa303de52",
            "f079c4d9ffcf40e687ed78a71ea45b17",
            "1c0ffa5673d74d618f13040b5c860da0",
            "f165db08018c484298b9349c1b4bc4b8",
            "e164a45641d044ebbe022027804faded",
            "72753eedda8f42b78275d30e92c26493",
            "63b23e799ab64fb0824f5404a6f207f6",
            "f0dc9ffebb394b099b0dfe8733126e18",
            "5cea755b34a3416d8e9d4a2941152e2d",
            "0bf9a11aa8ca4482809ffe7306514a6e",
            "dcdbf913031440c39a1925e60e6571da",
            "1c643513f5af443ea0b5bc14cc71198b",
            "d6a6a9098ac145faa6c142fc89a75b15",
            "76f2316ac0b54d27afc076599ccf4ac9",
            "31d798f77b6f4fcebb241fd4809ecfcd",
            "a6d54c174a2b42d99ec8839b62de5e71",
            "879e098c214b4981b3bd7285939c9f24",
            "bcd71e61ba114eb2a37dd78b66cf660f",
            "6e6517ff533c4611afc72af48c17d14f",
            "74d186a02f0f43fab3732fb107441e84",
            "5626b8aba29c49dab33ff1b8b95c1658",
            "4dfb8b27da27462a884f558c85b6e088",
            "5964ab981efa4a1ebc1297959affb267",
            "ad008230bee74380b20c9201c2d856b9",
            "8ead029340054d2ebb13b5ff4c7c56dc",
            "edf3da7571ce43ab8f2901230c6b0f5f",
            "50fdc97b7f4b4913b5553675a706aaa6"
          ]
        },
        "id": "PR05FUSCQcE7",
        "outputId": "c7fef246-d843-4a0c-b7cc-5ecae1b1fa32"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1235840e2ed447929e9b1fede396525a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)okenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "72753eedda8f42b78275d30e92c26493"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "879e098c214b4981b3bd7285939c9f24"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Load the pre-trained BERT model and tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Code to preprocess and tokenize the data"
      ],
      "metadata": {
        "id": "vBuAzRHPzJPe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ig_SB6xsNLMk"
      },
      "outputs": [],
      "source": [
        "def tokenizer_function(input_sequence):\n",
        "    \n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "        input_sequence,\n",
        "        add_special_tokens=True,\n",
        "        max_length=510,\n",
        "        padding='max_length',\n",
        "        return_attention_mask=True,\n",
        "        return_tensors='pt',\n",
        "        truncation='longest_first'\n",
        "    )\n",
        "\n",
        "    return encoded_dict\n",
        "    # train_input_ids.append(encoded_dict['input_ids'])\n",
        "    # train_attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "\n",
        "def extract_input_id(encoded_dict):\n",
        "  return encoded_dict['input_ids']\n",
        "def extract_attention_mask(encoded_dict):\n",
        "  return encoded_dict['attention_mask']\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RoSc9OG1fOBB"
      },
      "outputs": [],
      "source": [
        "# tokenizing and establishing attention masks for each of the input_texts in the training data\n",
        "\n",
        "raw_train_data['encoded_dict'] = raw_train_data['text'].apply(tokenizer_function)  \n",
        "raw_train_data['input_ids'] = raw_train_data['encoded_dict'].apply(extract_input_id)\n",
        "raw_train_data['attention_mask'] = raw_train_data['encoded_dict'].apply(extract_attention_mask)\n",
        "train_input_ids = torch.cat(list(raw_train_data['input_ids']), dim=0) \n",
        "train_attention_masks = torch.cat(list(raw_train_data['attention_mask']), dim=0)\n",
        "train_labels = torch.tensor(list(raw_train_data['sentiment']))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-oq1hKnyYXpB"
      },
      "outputs": [],
      "source": [
        "# Create a TensorDataset object from your training data\n",
        "train_dataset = TensorDataset(train_input_ids, train_attention_masks, train_labels) \n",
        "\n",
        "# Create a DataLoader object from your training dataset\n",
        "train_dataloader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=3,\n",
        "    shuffle=True,\n",
        "    num_workers=2,\n",
        "    drop_last=True\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train the model with a head"
      ],
      "metadata": {
        "id": "JUouOpDHzYHs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "e8afffa495c349f0a6c35a0949c964c6",
            "a8fbb85dd0bc4296be46c50dc4d233fa",
            "fd9948e393d746dca1308189ab653d26",
            "ca16270ceeff4a80a66cf82ef9f957ae",
            "1c7a59e699fb4f7698f4dab679716165",
            "5f4b7be7bfce4a8c9b5e200ddc6bce53",
            "3f4015d49aa24450a759d2f76651f384",
            "86e34cc0cdba4275816f247d3fa71506",
            "29b58ffaa04a405e9951e26073c88453",
            "798192db36a049ac8cc3066103d6e27f",
            "04b5cee4f8944b5c892cd4ee4524b8c0"
          ]
        },
        "id": "lupBI2t9XGaQ",
        "outputId": "c0ecf744-db61-4c19-bceb-f00b9469d95d"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading pytorch_model.bin:   0%|          | 0.00/440M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e8afffa495c349f0a6c35a0949c964c6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "For epoch: 0 and batch: 0, the time taken was: 21.048737049102783\n",
            "For epoch: 0 and batch: 1, the time taken was: 18.43476414680481\n",
            "For epoch: 0 and batch: 2, the time taken was: 17.915701627731323\n",
            "For epoch: 0 and batch: 3, the time taken was: 20.972858667373657\n",
            "For epoch: 0 and batch: 4, the time taken was: 17.817821264266968\n",
            "For epoch: 0 and batch: 5, the time taken was: 17.852327346801758\n",
            "For epoch: 0 and batch: 6, the time taken was: 17.8259015083313\n",
            "For epoch: 0 and batch: 7, the time taken was: 17.68736958503723\n",
            "For epoch: 0 and batch: 8, the time taken was: 17.584502935409546\n",
            "For epoch: 0 and batch: 9, the time taken was: 18.690935850143433\n",
            "For epoch: 0 and batch: 10, the time taken was: 18.803842544555664\n",
            "For epoch: 0 and batch: 11, the time taken was: 18.250309705734253\n",
            "For epoch: 0 and batch: 12, the time taken was: 17.802921772003174\n",
            "For epoch: 0 and batch: 13, the time taken was: 17.7690851688385\n",
            "For epoch: 0 and batch: 14, the time taken was: 17.640141010284424\n",
            "For epoch: 0 and batch: 15, the time taken was: 18.013983249664307\n",
            "For epoch: 0 and batch: 16, the time taken was: 17.97734785079956\n",
            "For epoch: 0 and batch: 17, the time taken was: 18.385584831237793\n",
            "For epoch: 0 and batch: 18, the time taken was: 18.247093439102173\n",
            "For epoch: 0 and batch: 19, the time taken was: 17.7320659160614\n",
            "For epoch: 0 and batch: 20, the time taken was: 17.634291410446167\n",
            "For epoch: 0 and batch: 21, the time taken was: 17.763095140457153\n",
            "For epoch: 0 and batch: 22, the time taken was: 17.603971242904663\n",
            "For epoch: 0 and batch: 23, the time taken was: 19.791774034500122\n",
            "For epoch: 0 and batch: 24, the time taken was: 18.908288717269897\n",
            "For epoch: 0 and batch: 25, the time taken was: 18.068838357925415\n",
            "For epoch: 0 and batch: 26, the time taken was: 18.032268285751343\n",
            "For epoch: 0 and batch: 27, the time taken was: 17.671306848526\n",
            "For epoch: 0 and batch: 28, the time taken was: 17.62305736541748\n",
            "For epoch: 0 and batch: 29, the time taken was: 17.513021230697632\n",
            "For epoch: 0 and batch: 30, the time taken was: 17.2707097530365\n",
            "For epoch: 0 and batch: 31, the time taken was: 18.480980157852173\n",
            "For epoch: 0 and batch: 32, the time taken was: 18.936943292617798\n",
            "For epoch: 0 and batch: 33, the time taken was: 18.43917417526245\n",
            "For epoch: 0 and batch: 34, the time taken was: 17.770478010177612\n",
            "For epoch: 0 and batch: 35, the time taken was: 17.695661067962646\n",
            "For epoch: 0 and batch: 36, the time taken was: 17.577914237976074\n",
            "For epoch: 0 and batch: 37, the time taken was: 17.04465341567993\n",
            "For epoch: 0 and batch: 38, the time taken was: 17.74211573600769\n",
            "For epoch: 0 and batch: 39, the time taken was: 17.873899221420288\n",
            "For epoch: 0 and batch: 40, the time taken was: 18.608445167541504\n",
            "For epoch: 0 and batch: 41, the time taken was: 17.983182191848755\n",
            "For epoch: 0 and batch: 42, the time taken was: 17.309420585632324\n",
            "For epoch: 0 and batch: 43, the time taken was: 17.598867416381836\n",
            "For epoch: 0 and batch: 44, the time taken was: 17.559507608413696\n",
            "For epoch: 0 and batch: 45, the time taken was: 17.413689136505127\n",
            "For epoch: 0 and batch: 46, the time taken was: 17.571359395980835\n",
            "For epoch: 0 and batch: 47, the time taken was: 18.256211042404175\n",
            "For epoch: 0 and batch: 48, the time taken was: 18.095221042633057\n",
            "For epoch: 0 and batch: 49, the time taken was: 18.069164037704468\n",
            "For epoch: 0 and batch: 50, the time taken was: 17.973787307739258\n",
            "For epoch: 0 and batch: 51, the time taken was: 18.109402656555176\n",
            "For epoch: 0 and batch: 52, the time taken was: 17.980305433273315\n",
            "For epoch: 0 and batch: 53, the time taken was: 17.43154764175415\n",
            "For epoch: 0 and batch: 54, the time taken was: 18.116700887680054\n",
            "For epoch: 0 and batch: 55, the time taken was: 18.246792793273926\n",
            "For epoch: 0 and batch: 56, the time taken was: 18.188685178756714\n",
            "For epoch: 0 and batch: 57, the time taken was: 19.567851781845093\n",
            "For epoch: 0 and batch: 58, the time taken was: 18.305598974227905\n",
            "For epoch: 0 and batch: 59, the time taken was: 17.842572689056396\n",
            "For epoch: 0 and batch: 60, the time taken was: 17.447771549224854\n",
            "For epoch: 0 and batch: 61, the time taken was: 17.56785535812378\n",
            "For epoch: 0 and batch: 62, the time taken was: 18.694571018218994\n",
            "For epoch: 0 and batch: 63, the time taken was: 18.195518255233765\n",
            "For epoch: 0 and batch: 64, the time taken was: 17.6353178024292\n",
            "For epoch: 0 and batch: 65, the time taken was: 17.449937343597412\n",
            "For epoch: 0 and batch: 66, the time taken was: 17.49978733062744\n",
            "For epoch: 0 and batch: 67, the time taken was: 17.955724239349365\n",
            "For epoch: 0 and batch: 68, the time taken was: 17.352111101150513\n",
            "For epoch: 0 and batch: 69, the time taken was: 17.522501707077026\n",
            "For epoch: 0 and batch: 70, the time taken was: 18.84284543991089\n",
            "For epoch: 0 and batch: 71, the time taken was: 18.36434841156006\n",
            "For epoch: 0 and batch: 72, the time taken was: 17.594087839126587\n",
            "For epoch: 0 and batch: 73, the time taken was: 17.905483722686768\n",
            "For epoch: 0 and batch: 74, the time taken was: 17.967108488082886\n",
            "For epoch: 0 and batch: 75, the time taken was: 17.65576410293579\n",
            "For epoch: 0 and batch: 76, the time taken was: 17.23195791244507\n",
            "For epoch: 0 and batch: 77, the time taken was: 17.9393093585968\n",
            "For epoch: 0 and batch: 78, the time taken was: 17.950315713882446\n",
            "For epoch: 0 and batch: 79, the time taken was: 18.116674661636353\n",
            "For epoch: 0 and batch: 80, the time taken was: 17.488909244537354\n",
            "For epoch: 0 and batch: 81, the time taken was: 17.88453722000122\n",
            "For epoch: 0 and batch: 82, the time taken was: 17.488672733306885\n",
            "For epoch: 0 and batch: 83, the time taken was: 17.573795795440674\n",
            "For epoch: 0 and batch: 84, the time taken was: 17.657078742980957\n",
            "For epoch: 0 and batch: 85, the time taken was: 17.83650493621826\n",
            "For epoch: 0 and batch: 86, the time taken was: 17.953001976013184\n",
            "For epoch: 0 and batch: 87, the time taken was: 18.91897439956665\n",
            "For epoch: 0 and batch: 88, the time taken was: 17.57218885421753\n",
            "For epoch: 0 and batch: 89, the time taken was: 17.870887279510498\n",
            "For epoch: 0 and batch: 90, the time taken was: 17.605814218521118\n",
            "For epoch: 0 and batch: 91, the time taken was: 20.109249353408813\n",
            "For epoch: 0 and batch: 92, the time taken was: 18.03280520439148\n",
            "For epoch: 0 and batch: 93, the time taken was: 18.160234689712524\n",
            "For epoch: 0 and batch: 94, the time taken was: 18.18129301071167\n",
            "For epoch: 0 and batch: 95, the time taken was: 17.75784969329834\n",
            "For epoch: 0 and batch: 96, the time taken was: 17.561940670013428\n",
            "For epoch: 0 and batch: 97, the time taken was: 17.658628940582275\n",
            "For epoch: 0 and batch: 98, the time taken was: 17.59715962409973\n",
            "For epoch: 0 and batch: 99, the time taken was: 17.889267683029175\n",
            "For epoch: 0 and batch: 100, the time taken was: 18.202194452285767\n",
            "For epoch: 0 and batch: 101, the time taken was: 18.22452664375305\n",
            "For epoch: 0 and batch: 102, the time taken was: 17.958563804626465\n",
            "For epoch: 0 and batch: 103, the time taken was: 17.67056393623352\n",
            "For epoch: 0 and batch: 104, the time taken was: 18.154725551605225\n",
            "For epoch: 0 and batch: 105, the time taken was: 17.55145263671875\n",
            "For epoch: 0 and batch: 106, the time taken was: 17.39874505996704\n",
            "For epoch: 0 and batch: 107, the time taken was: 17.372122049331665\n",
            "For epoch: 0 and batch: 108, the time taken was: 18.082447052001953\n",
            "For epoch: 0 and batch: 109, the time taken was: 18.1933114528656\n",
            "For epoch: 0 and batch: 110, the time taken was: 17.717496156692505\n",
            "For epoch: 0 and batch: 111, the time taken was: 17.593644380569458\n",
            "For epoch: 0 and batch: 112, the time taken was: 17.58540439605713\n",
            "For epoch: 0 and batch: 113, the time taken was: 17.7755708694458\n",
            "For epoch: 0 and batch: 114, the time taken was: 17.525703191757202\n",
            "For epoch: 0 and batch: 115, the time taken was: 17.516737937927246\n",
            "For epoch: 0 and batch: 116, the time taken was: 18.428030252456665\n",
            "For epoch: 0 and batch: 117, the time taken was: 17.877666234970093\n",
            "For epoch: 0 and batch: 118, the time taken was: 17.956355333328247\n",
            "For epoch: 0 and batch: 119, the time taken was: 17.62856936454773\n",
            "For epoch: 0 and batch: 120, the time taken was: 17.59183669090271\n",
            "For epoch: 0 and batch: 121, the time taken was: 17.814466953277588\n",
            "For epoch: 0 and batch: 122, the time taken was: 17.505400896072388\n",
            "For epoch: 0 and batch: 123, the time taken was: 17.56758403778076\n",
            "For epoch: 0 and batch: 124, the time taken was: 17.60222816467285\n",
            "For epoch: 0 and batch: 125, the time taken was: 18.300920486450195\n",
            "For epoch: 0 and batch: 126, the time taken was: 18.20225238800049\n",
            "For epoch: 0 and batch: 127, the time taken was: 17.639590978622437\n",
            "For epoch: 0 and batch: 128, the time taken was: 17.64327907562256\n",
            "For epoch: 0 and batch: 129, the time taken was: 17.63841152191162\n",
            "For epoch: 0 and batch: 130, the time taken was: 17.983042240142822\n",
            "For epoch: 0 and batch: 131, the time taken was: 17.47048330307007\n",
            "For epoch: 0 and batch: 132, the time taken was: 18.599849700927734\n",
            "For epoch: 0 and batch: 133, the time taken was: 18.700407028198242\n",
            "For epoch: 0 and batch: 134, the time taken was: 17.706427812576294\n",
            "For epoch: 0 and batch: 135, the time taken was: 18.217286348342896\n",
            "For epoch: 0 and batch: 136, the time taken was: 17.491586446762085\n",
            "For epoch: 0 and batch: 137, the time taken was: 17.453059673309326\n",
            "For epoch: 0 and batch: 138, the time taken was: 17.4649019241333\n",
            "For epoch: 0 and batch: 139, the time taken was: 17.593793869018555\n",
            "For epoch: 0 and batch: 140, the time taken was: 18.28681254386902\n",
            "For epoch: 0 and batch: 141, the time taken was: 17.954082250595093\n",
            "For epoch: 0 and batch: 142, the time taken was: 17.86127018928528\n",
            "For epoch: 0 and batch: 143, the time taken was: 17.95932698249817\n",
            "For epoch: 0 and batch: 144, the time taken was: 17.620184898376465\n",
            "For epoch: 0 and batch: 145, the time taken was: 20.587880611419678\n",
            "For epoch: 0 and batch: 146, the time taken was: 19.828498125076294\n",
            "For epoch: 0 and batch: 147, the time taken was: 19.216877222061157\n",
            "For epoch: 0 and batch: 148, the time taken was: 17.857300519943237\n",
            "For epoch: 0 and batch: 149, the time taken was: 17.684610605239868\n",
            "For epoch: 0 and batch: 150, the time taken was: 17.89048719406128\n",
            "For epoch: 0 and batch: 151, the time taken was: 18.071484804153442\n",
            "For epoch: 0 and batch: 152, the time taken was: 17.990403652191162\n",
            "For epoch: 0 and batch: 153, the time taken was: 17.947964191436768\n",
            "For epoch: 0 and batch: 154, the time taken was: 18.461652278900146\n",
            "For epoch: 0 and batch: 155, the time taken was: 17.998802423477173\n",
            "For epoch: 0 and batch: 156, the time taken was: 17.604434967041016\n",
            "For epoch: 0 and batch: 157, the time taken was: 17.541823625564575\n",
            "For epoch: 0 and batch: 158, the time taken was: 17.679483652114868\n",
            "For epoch: 0 and batch: 159, the time taken was: 17.853707313537598\n",
            "For epoch: 0 and batch: 160, the time taken was: 17.73240375518799\n",
            "For epoch: 0 and batch: 161, the time taken was: 18.165761947631836\n",
            "For epoch: 0 and batch: 162, the time taken was: 19.03735089302063\n",
            "For epoch: 0 and batch: 163, the time taken was: 17.621525526046753\n",
            "For epoch: 0 and batch: 164, the time taken was: 17.660731554031372\n",
            "For epoch: 0 and batch: 165, the time taken was: 17.656869173049927\n",
            "For epoch: 0 and batch: 166, the time taken was: 17.50748038291931\n",
            "For epoch: 0 and batch: 167, the time taken was: 17.372124671936035\n",
            "For epoch: 0 and batch: 168, the time taken was: 17.369449615478516\n",
            "For epoch: 0 and batch: 169, the time taken was: 17.95973777770996\n",
            "For epoch: 0 and batch: 170, the time taken was: 18.10108208656311\n",
            "For epoch: 0 and batch: 171, the time taken was: 18.190946340560913\n",
            "For epoch: 0 and batch: 172, the time taken was: 17.67564368247986\n",
            "For epoch: 0 and batch: 173, the time taken was: 17.591142892837524\n",
            "For epoch: 0 and batch: 174, the time taken was: 17.916223287582397\n",
            "For epoch: 0 and batch: 175, the time taken was: 17.565738439559937\n",
            "For epoch: 0 and batch: 176, the time taken was: 17.325359344482422\n",
            "For epoch: 0 and batch: 177, the time taken was: 17.68224048614502\n",
            "For epoch: 0 and batch: 178, the time taken was: 18.358306646347046\n",
            "For epoch: 0 and batch: 179, the time taken was: 18.17772626876831\n",
            "For epoch: 0 and batch: 180, the time taken was: 17.725595951080322\n",
            "For epoch: 0 and batch: 181, the time taken was: 17.716490983963013\n",
            "For epoch: 0 and batch: 182, the time taken was: 17.761263608932495\n",
            "For epoch: 0 and batch: 183, the time taken was: 17.542083501815796\n",
            "For epoch: 0 and batch: 184, the time taken was: 17.641141414642334\n",
            "For epoch: 0 and batch: 185, the time taken was: 18.294813871383667\n",
            "For epoch: 0 and batch: 186, the time taken was: 18.620995044708252\n",
            "For epoch: 0 and batch: 187, the time taken was: 18.41379451751709\n",
            "For epoch: 0 and batch: 188, the time taken was: 17.95480442047119\n",
            "For epoch: 0 and batch: 189, the time taken was: 17.838170766830444\n",
            "For epoch: 0 and batch: 190, the time taken was: 18.020978212356567\n",
            "For epoch: 0 and batch: 191, the time taken was: 18.19252920150757\n",
            "For epoch: 0 and batch: 192, the time taken was: 18.136903285980225\n",
            "For epoch: 0 and batch: 193, the time taken was: 19.03031849861145\n",
            "For epoch: 0 and batch: 194, the time taken was: 18.342000484466553\n",
            "For epoch: 0 and batch: 195, the time taken was: 17.930628061294556\n",
            "For epoch: 0 and batch: 196, the time taken was: 17.84645986557007\n",
            "For epoch: 0 and batch: 197, the time taken was: 17.52849769592285\n",
            "For epoch: 0 and batch: 198, the time taken was: 17.47827458381653\n",
            "For epoch: 0 and batch: 199, the time taken was: 17.562323570251465\n",
            "For epoch: 0 and batch: 200, the time taken was: 18.345868349075317\n",
            "For epoch: 0 and batch: 201, the time taken was: 18.204707145690918\n",
            "For epoch: 0 and batch: 202, the time taken was: 17.96694278717041\n",
            "For epoch: 0 and batch: 203, the time taken was: 17.79572343826294\n",
            "For epoch: 0 and batch: 204, the time taken was: 17.575366973876953\n",
            "For epoch: 0 and batch: 205, the time taken was: 17.687562942504883\n",
            "For epoch: 0 and batch: 206, the time taken was: 17.542340517044067\n",
            "For epoch: 0 and batch: 207, the time taken was: 17.397608518600464\n",
            "For epoch: 0 and batch: 208, the time taken was: 17.93074369430542\n",
            "For epoch: 0 and batch: 209, the time taken was: 18.442970514297485\n",
            "For epoch: 0 and batch: 210, the time taken was: 17.83581256866455\n",
            "For epoch: 0 and batch: 211, the time taken was: 17.65227484703064\n",
            "For epoch: 0 and batch: 212, the time taken was: 17.97371768951416\n",
            "For epoch: 0 and batch: 213, the time taken was: 17.628915786743164\n",
            "For epoch: 0 and batch: 214, the time taken was: 17.558831453323364\n",
            "For epoch: 0 and batch: 215, the time taken was: 17.353646516799927\n",
            "For epoch: 0 and batch: 216, the time taken was: 18.083580255508423\n",
            "For epoch: 0 and batch: 217, the time taken was: 18.099650144577026\n",
            "For epoch: 0 and batch: 218, the time taken was: 18.072087287902832\n",
            "For epoch: 0 and batch: 219, the time taken was: 17.55219531059265\n",
            "For epoch: 0 and batch: 220, the time taken was: 17.95425033569336\n",
            "For epoch: 0 and batch: 221, the time taken was: 17.468292236328125\n",
            "For epoch: 0 and batch: 222, the time taken was: 17.39123225212097\n",
            "For epoch: 0 and batch: 223, the time taken was: 17.30265784263611\n",
            "For epoch: 0 and batch: 224, the time taken was: 18.04288959503174\n",
            "For epoch: 0 and batch: 225, the time taken was: 18.187859773635864\n",
            "For epoch: 0 and batch: 226, the time taken was: 17.8546245098114\n",
            "For epoch: 0 and batch: 227, the time taken was: 17.907480478286743\n",
            "For epoch: 0 and batch: 228, the time taken was: 17.4836905002594\n",
            "For epoch: 0 and batch: 229, the time taken was: 17.41622829437256\n",
            "For epoch: 0 and batch: 230, the time taken was: 17.615747451782227\n",
            "For epoch: 0 and batch: 231, the time taken was: 17.328969717025757\n",
            "For epoch: 0 and batch: 232, the time taken was: 17.630443572998047\n",
            "For epoch: 0 and batch: 233, the time taken was: 17.973153829574585\n",
            "For epoch: 0 and batch: 234, the time taken was: 18.123306035995483\n",
            "For epoch: 0 and batch: 235, the time taken was: 17.80251407623291\n",
            "For epoch: 0 and batch: 236, the time taken was: 17.532429695129395\n",
            "For epoch: 0 and batch: 237, the time taken was: 17.81767201423645\n",
            "For epoch: 0 and batch: 238, the time taken was: 17.998389959335327\n",
            "For epoch: 0 and batch: 239, the time taken was: 17.85514783859253\n",
            "For epoch: 0 and batch: 240, the time taken was: 17.119561910629272\n",
            "For epoch: 0 and batch: 241, the time taken was: 18.628172159194946\n",
            "For epoch: 0 and batch: 242, the time taken was: 18.86730670928955\n",
            "For epoch: 0 and batch: 243, the time taken was: 17.670952320098877\n",
            "For epoch: 0 and batch: 244, the time taken was: 17.681796073913574\n",
            "For epoch: 0 and batch: 245, the time taken was: 17.59661602973938\n",
            "For epoch: 0 and batch: 246, the time taken was: 17.88032341003418\n",
            "For epoch: 0 and batch: 247, the time taken was: 17.45792555809021\n",
            "For epoch: 0 and batch: 248, the time taken was: 17.385143995285034\n",
            "For epoch: 0 and batch: 249, the time taken was: 17.986919403076172\n",
            "For epoch: 0 and batch: 250, the time taken was: 18.23166513442993\n",
            "For epoch: 0 and batch: 251, the time taken was: 17.873770236968994\n",
            "For epoch: 0 and batch: 252, the time taken was: 17.625081062316895\n",
            "For epoch: 0 and batch: 253, the time taken was: 17.482712745666504\n",
            "For epoch: 0 and batch: 254, the time taken was: 17.52924132347107\n",
            "For epoch: 0 and batch: 255, the time taken was: 17.25623059272766\n",
            "For epoch: 0 and batch: 256, the time taken was: 17.341296911239624\n",
            "For epoch: 0 and batch: 257, the time taken was: 17.324411153793335\n",
            "For epoch: 0 and batch: 258, the time taken was: 17.78014588356018\n",
            "For epoch: 0 and batch: 259, the time taken was: 18.274485111236572\n",
            "For epoch: 0 and batch: 260, the time taken was: 17.866772174835205\n",
            "For epoch: 0 and batch: 261, the time taken was: 17.556955575942993\n",
            "For epoch: 0 and batch: 262, the time taken was: 17.45518183708191\n",
            "For epoch: 0 and batch: 263, the time taken was: 18.038947582244873\n",
            "For epoch: 0 and batch: 264, the time taken was: 17.807310819625854\n",
            "For epoch: 0 and batch: 265, the time taken was: 17.371835231781006\n",
            "For epoch: 0 and batch: 266, the time taken was: 18.097184658050537\n",
            "For epoch: 0 and batch: 267, the time taken was: 18.075698375701904\n",
            "For epoch: 0 and batch: 268, the time taken was: 18.27979278564453\n",
            "For epoch: 0 and batch: 269, the time taken was: 17.59160566329956\n",
            "For epoch: 0 and batch: 270, the time taken was: 17.425029039382935\n",
            "For epoch: 0 and batch: 271, the time taken was: 17.87142062187195\n",
            "For epoch: 0 and batch: 272, the time taken was: 17.757137775421143\n",
            "For epoch: 0 and batch: 273, the time taken was: 17.41371989250183\n",
            "For epoch: 0 and batch: 274, the time taken was: 17.926957845687866\n",
            "For epoch: 0 and batch: 275, the time taken was: 17.998189687728882\n",
            "For epoch: 0 and batch: 276, the time taken was: 18.117390394210815\n",
            "For epoch: 0 and batch: 277, the time taken was: 17.569034337997437\n",
            "For epoch: 0 and batch: 278, the time taken was: 17.755637884140015\n",
            "For epoch: 0 and batch: 279, the time taken was: 17.65334677696228\n",
            "For epoch: 0 and batch: 280, the time taken was: 17.90944004058838\n",
            "For epoch: 0 and batch: 281, the time taken was: 17.4047749042511\n",
            "For epoch: 0 and batch: 282, the time taken was: 17.761390686035156\n",
            "For epoch: 0 and batch: 283, the time taken was: 18.293375492095947\n",
            "For epoch: 0 and batch: 284, the time taken was: 18.02919101715088\n",
            "For epoch: 0 and batch: 285, the time taken was: 17.723414421081543\n",
            "For epoch: 0 and batch: 286, the time taken was: 17.574644327163696\n",
            "For epoch: 0 and batch: 287, the time taken was: 17.5093674659729\n",
            "For epoch: 0 and batch: 288, the time taken was: 17.60516881942749\n",
            "For epoch: 0 and batch: 289, the time taken was: 17.482818603515625\n",
            "For epoch: 0 and batch: 290, the time taken was: 17.493797779083252\n",
            "For epoch: 0 and batch: 291, the time taken was: 18.33123254776001\n",
            "For epoch: 0 and batch: 292, the time taken was: 18.514527797698975\n",
            "For epoch: 0 and batch: 293, the time taken was: 17.86695432662964\n",
            "For epoch: 0 and batch: 294, the time taken was: 17.713045835494995\n",
            "For epoch: 0 and batch: 295, the time taken was: 17.76813840866089\n",
            "For epoch: 0 and batch: 296, the time taken was: 17.596879959106445\n",
            "For epoch: 0 and batch: 297, the time taken was: 17.565906524658203\n",
            "For epoch: 0 and batch: 298, the time taken was: 17.51154112815857\n",
            "For epoch: 0 and batch: 299, the time taken was: 18.314964294433594\n",
            "For epoch: 0 and batch: 300, the time taken was: 18.120319366455078\n",
            "For epoch: 0 and batch: 301, the time taken was: 17.603765964508057\n",
            "For epoch: 0 and batch: 302, the time taken was: 17.4635169506073\n",
            "For epoch: 0 and batch: 303, the time taken was: 17.616943836212158\n",
            "For epoch: 0 and batch: 304, the time taken was: 17.70188045501709\n",
            "For epoch: 0 and batch: 305, the time taken was: 17.584593057632446\n",
            "For epoch: 0 and batch: 306, the time taken was: 17.475338459014893\n",
            "For epoch: 0 and batch: 307, the time taken was: 17.79075050354004\n",
            "For epoch: 0 and batch: 308, the time taken was: 18.28393530845642\n",
            "For epoch: 0 and batch: 309, the time taken was: 18.064600467681885\n",
            "For epoch: 0 and batch: 310, the time taken was: 17.894297122955322\n",
            "For epoch: 0 and batch: 311, the time taken was: 17.489823579788208\n",
            "For epoch: 0 and batch: 312, the time taken was: 17.863335132598877\n",
            "For epoch: 0 and batch: 313, the time taken was: 17.503583908081055\n",
            "For epoch: 0 and batch: 314, the time taken was: 17.732354879379272\n",
            "For epoch: 0 and batch: 315, the time taken was: 17.902463674545288\n",
            "For epoch: 0 and batch: 316, the time taken was: 18.07040548324585\n",
            "For epoch: 0 and batch: 317, the time taken was: 17.94736385345459\n",
            "For epoch: 0 and batch: 318, the time taken was: 17.455005645751953\n",
            "For epoch: 0 and batch: 319, the time taken was: 17.55048894882202\n",
            "For epoch: 0 and batch: 320, the time taken was: 17.539864778518677\n",
            "For epoch: 0 and batch: 321, the time taken was: 17.43699049949646\n",
            "For epoch: 0 and batch: 322, the time taken was: 17.337108612060547\n",
            "For epoch: 0 and batch: 323, the time taken was: 17.334990978240967\n",
            "For epoch: 0 and batch: 324, the time taken was: 17.743842124938965\n",
            "For epoch: 0 and batch: 325, the time taken was: 18.128315210342407\n",
            "For epoch: 0 and batch: 326, the time taken was: 18.022505283355713\n",
            "For epoch: 0 and batch: 327, the time taken was: 17.494460344314575\n",
            "For epoch: 0 and batch: 328, the time taken was: 17.784517765045166\n",
            "For epoch: 0 and batch: 329, the time taken was: 17.578047037124634\n",
            "For epoch: 0 and batch: 330, the time taken was: 17.5716655254364\n",
            "For epoch: 0 and batch: 331, the time taken was: 17.356453895568848\n",
            "For epoch: 0 and batch: 332, the time taken was: 17.359805822372437\n",
            "For epoch: 0 and batch: 333, the time taken was: 18.001925706863403\n",
            "For epoch: 0 and batch: 334, the time taken was: 18.313328504562378\n",
            "For epoch: 0 and batch: 335, the time taken was: 17.691612720489502\n",
            "For epoch: 0 and batch: 336, the time taken was: 17.574864625930786\n",
            "For epoch: 0 and batch: 337, the time taken was: 17.524974584579468\n",
            "For epoch: 0 and batch: 338, the time taken was: 17.495014667510986\n",
            "For epoch: 0 and batch: 339, the time taken was: 17.730295181274414\n",
            "For epoch: 0 and batch: 340, the time taken was: 17.79714012145996\n",
            "For epoch: 0 and batch: 341, the time taken was: 18.40785002708435\n",
            "For epoch: 0 and batch: 342, the time taken was: 18.229002237319946\n",
            "For epoch: 0 and batch: 343, the time taken was: 18.198344945907593\n",
            "For epoch: 0 and batch: 344, the time taken was: 17.732754468917847\n",
            "For epoch: 0 and batch: 345, the time taken was: 17.85076665878296\n",
            "For epoch: 0 and batch: 346, the time taken was: 17.443989992141724\n",
            "For epoch: 0 and batch: 347, the time taken was: 17.45025897026062\n",
            "For epoch: 0 and batch: 348, the time taken was: 17.65671420097351\n",
            "For epoch: 0 and batch: 349, the time taken was: 18.758129358291626\n",
            "For epoch: 0 and batch: 350, the time taken was: 18.788394689559937\n",
            "For epoch: 0 and batch: 351, the time taken was: 17.479745864868164\n",
            "For epoch: 0 and batch: 352, the time taken was: 17.47608184814453\n",
            "For epoch: 0 and batch: 353, the time taken was: 17.34265398979187\n",
            "For epoch: 0 and batch: 354, the time taken was: 17.6788170337677\n",
            "For epoch: 0 and batch: 355, the time taken was: 17.8386652469635\n",
            "For epoch: 0 and batch: 356, the time taken was: 17.380924940109253\n",
            "For epoch: 0 and batch: 357, the time taken was: 18.016839027404785\n",
            "For epoch: 0 and batch: 358, the time taken was: 18.36402940750122\n",
            "For epoch: 0 and batch: 359, the time taken was: 18.220248699188232\n",
            "For epoch: 0 and batch: 360, the time taken was: 17.606337308883667\n",
            "For epoch: 0 and batch: 361, the time taken was: 17.850602388381958\n",
            "For epoch: 0 and batch: 362, the time taken was: 17.57001042366028\n",
            "For epoch: 0 and batch: 363, the time taken was: 17.74571919441223\n",
            "For epoch: 0 and batch: 364, the time taken was: 17.391698360443115\n",
            "For epoch: 0 and batch: 365, the time taken was: 17.86950922012329\n",
            "For epoch: 0 and batch: 366, the time taken was: 18.21514344215393\n",
            "For epoch: 0 and batch: 367, the time taken was: 18.120864152908325\n",
            "For epoch: 0 and batch: 368, the time taken was: 17.820895671844482\n",
            "For epoch: 0 and batch: 369, the time taken was: 17.52013897895813\n",
            "For epoch: 0 and batch: 370, the time taken was: 17.5468692779541\n",
            "For epoch: 0 and batch: 371, the time taken was: 17.350191831588745\n",
            "For epoch: 0 and batch: 372, the time taken was: 17.34062147140503\n",
            "For epoch: 0 and batch: 373, the time taken was: 17.33712935447693\n",
            "For epoch: 0 and batch: 374, the time taken was: 17.652170181274414\n",
            "For epoch: 0 and batch: 375, the time taken was: 17.839723587036133\n",
            "For epoch: 0 and batch: 376, the time taken was: 17.852346897125244\n",
            "For epoch: 0 and batch: 377, the time taken was: 17.50542140007019\n",
            "For epoch: 0 and batch: 378, the time taken was: 17.401986122131348\n",
            "For epoch: 0 and batch: 379, the time taken was: 17.398237466812134\n",
            "For epoch: 0 and batch: 380, the time taken was: 17.67575240135193\n",
            "For epoch: 0 and batch: 381, the time taken was: 17.426931619644165\n",
            "For epoch: 0 and batch: 382, the time taken was: 17.295698404312134\n",
            "For epoch: 0 and batch: 383, the time taken was: 18.189128875732422\n",
            "For epoch: 0 and batch: 384, the time taken was: 18.310355186462402\n",
            "For epoch: 0 and batch: 385, the time taken was: 17.884888172149658\n",
            "For epoch: 0 and batch: 386, the time taken was: 17.76186490058899\n",
            "For epoch: 0 and batch: 387, the time taken was: 17.506268978118896\n",
            "For epoch: 0 and batch: 388, the time taken was: 17.92848229408264\n",
            "For epoch: 0 and batch: 389, the time taken was: 17.94391131401062\n",
            "For epoch: 0 and batch: 390, the time taken was: 17.77095627784729\n",
            "For epoch: 0 and batch: 391, the time taken was: 18.297499895095825\n",
            "For epoch: 0 and batch: 392, the time taken was: 18.35642409324646\n",
            "For epoch: 0 and batch: 393, the time taken was: 17.778565645217896\n",
            "For epoch: 0 and batch: 394, the time taken was: 17.604748487472534\n",
            "For epoch: 0 and batch: 395, the time taken was: 17.033271551132202\n",
            "For epoch: 0 and batch: 396, the time taken was: 17.570952653884888\n",
            "For epoch: 0 and batch: 397, the time taken was: 17.782047748565674\n",
            "For epoch: 0 and batch: 398, the time taken was: 17.412636041641235\n",
            "For epoch: 0 and batch: 399, the time taken was: 17.653935194015503\n",
            "For epoch: 0 and batch: 400, the time taken was: 18.184316396713257\n",
            "For epoch: 0 and batch: 401, the time taken was: 18.083354473114014\n",
            "For epoch: 0 and batch: 402, the time taken was: 17.839414358139038\n",
            "For epoch: 0 and batch: 403, the time taken was: 17.639063835144043\n",
            "For epoch: 0 and batch: 404, the time taken was: 17.563020706176758\n",
            "For epoch: 0 and batch: 405, the time taken was: 17.692402362823486\n",
            "For epoch: 0 and batch: 406, the time taken was: 17.46319055557251\n",
            "For epoch: 0 and batch: 407, the time taken was: 17.7769672870636\n",
            "For epoch: 0 and batch: 408, the time taken was: 18.17034125328064\n",
            "For epoch: 0 and batch: 409, the time taken was: 18.155107498168945\n",
            "For epoch: 0 and batch: 410, the time taken was: 17.585768699645996\n",
            "For epoch: 0 and batch: 411, the time taken was: 17.858076572418213\n",
            "For epoch: 0 and batch: 412, the time taken was: 17.580816745758057\n",
            "For epoch: 0 and batch: 413, the time taken was: 18.113266229629517\n",
            "For epoch: 0 and batch: 414, the time taken was: 17.613070726394653\n",
            "For epoch: 0 and batch: 415, the time taken was: 18.365702152252197\n",
            "For epoch: 0 and batch: 416, the time taken was: 18.12207055091858\n",
            "For epoch: 0 and batch: 417, the time taken was: 17.886441707611084\n",
            "For epoch: 0 and batch: 418, the time taken was: 17.524250268936157\n",
            "For epoch: 0 and batch: 419, the time taken was: 17.842166423797607\n",
            "For epoch: 0 and batch: 420, the time taken was: 17.590949773788452\n",
            "For epoch: 0 and batch: 421, the time taken was: 17.683837890625\n",
            "For epoch: 0 and batch: 422, the time taken was: 17.654146194458008\n",
            "For epoch: 0 and batch: 423, the time taken was: 17.499974489212036\n",
            "For epoch: 0 and batch: 424, the time taken was: 18.492769956588745\n",
            "For epoch: 0 and batch: 425, the time taken was: 18.155616521835327\n",
            "For epoch: 0 and batch: 426, the time taken was: 17.5876522064209\n",
            "For epoch: 0 and batch: 427, the time taken was: 17.779168367385864\n",
            "For epoch: 0 and batch: 428, the time taken was: 17.63398313522339\n",
            "For epoch: 0 and batch: 429, the time taken was: 17.492802143096924\n",
            "For epoch: 0 and batch: 430, the time taken was: 17.648564338684082\n",
            "For epoch: 0 and batch: 431, the time taken was: 17.499860525131226\n",
            "For epoch: 0 and batch: 432, the time taken was: 17.610113859176636\n",
            "For epoch: 0 and batch: 433, the time taken was: 18.76651930809021\n",
            "For epoch: 0 and batch: 434, the time taken was: 18.207618713378906\n",
            "For epoch: 0 and batch: 435, the time taken was: 17.665061712265015\n",
            "For epoch: 0 and batch: 436, the time taken was: 17.754581689834595\n",
            "For epoch: 0 and batch: 437, the time taken was: 17.5694100856781\n",
            "For epoch: 0 and batch: 438, the time taken was: 18.01850724220276\n",
            "For epoch: 0 and batch: 439, the time taken was: 17.529321908950806\n",
            "For epoch: 0 and batch: 440, the time taken was: 18.23065972328186\n",
            "For epoch: 0 and batch: 441, the time taken was: 18.183894395828247\n",
            "For epoch: 0 and batch: 442, the time taken was: 17.713531970977783\n",
            "For epoch: 0 and batch: 443, the time taken was: 17.563148498535156\n",
            "For epoch: 0 and batch: 444, the time taken was: 17.61561608314514\n",
            "For epoch: 0 and batch: 445, the time taken was: 17.594614028930664\n",
            "For epoch: 0 and batch: 446, the time taken was: 17.20607328414917\n",
            "For epoch: 0 and batch: 447, the time taken was: 17.459548711776733\n",
            "For epoch: 0 and batch: 448, the time taken was: 18.439032316207886\n",
            "For epoch: 0 and batch: 449, the time taken was: 18.613398551940918\n",
            "For epoch: 0 and batch: 450, the time taken was: 18.275092124938965\n",
            "For epoch: 0 and batch: 451, the time taken was: 17.972099542617798\n",
            "For epoch: 0 and batch: 452, the time taken was: 17.92809510231018\n",
            "For epoch: 0 and batch: 453, the time taken was: 17.483697652816772\n",
            "For epoch: 0 and batch: 454, the time taken was: 17.335087060928345\n",
            "For epoch: 0 and batch: 455, the time taken was: 16.950422763824463\n",
            "For epoch: 0 and batch: 456, the time taken was: 17.714370489120483\n",
            "For epoch: 0 and batch: 457, the time taken was: 18.314748287200928\n",
            "For epoch: 0 and batch: 458, the time taken was: 18.055705547332764\n",
            "For epoch: 0 and batch: 459, the time taken was: 17.67243504524231\n",
            "For epoch: 0 and batch: 460, the time taken was: 17.484051942825317\n",
            "For epoch: 0 and batch: 461, the time taken was: 17.86528491973877\n",
            "For epoch: 0 and batch: 462, the time taken was: 17.449408531188965\n",
            "For epoch: 0 and batch: 463, the time taken was: 17.35129976272583\n",
            "For epoch: 0 and batch: 464, the time taken was: 17.49154829978943\n",
            "For epoch: 0 and batch: 465, the time taken was: 18.070322513580322\n",
            "For epoch: 0 and batch: 466, the time taken was: 18.00435185432434\n",
            "For epoch: 0 and batch: 467, the time taken was: 17.699357748031616\n",
            "For epoch: 0 and batch: 468, the time taken was: 17.45341682434082\n",
            "For epoch: 0 and batch: 469, the time taken was: 17.48875117301941\n",
            "For epoch: 0 and batch: 470, the time taken was: 17.577707529067993\n",
            "For epoch: 0 and batch: 471, the time taken was: 17.571401357650757\n",
            "For epoch: 0 and batch: 472, the time taken was: 17.623032808303833\n",
            "For epoch: 0 and batch: 473, the time taken was: 17.800098419189453\n",
            "For epoch: 0 and batch: 474, the time taken was: 18.46461319923401\n",
            "For epoch: 0 and batch: 475, the time taken was: 17.924686908721924\n",
            "For epoch: 0 and batch: 476, the time taken was: 17.85205340385437\n",
            "For epoch: 0 and batch: 477, the time taken was: 17.45362377166748\n",
            "For epoch: 0 and batch: 478, the time taken was: 17.609394073486328\n",
            "For epoch: 0 and batch: 479, the time taken was: 17.5641770362854\n",
            "For epoch: 0 and batch: 480, the time taken was: 17.310500383377075\n",
            "For epoch: 0 and batch: 481, the time taken was: 17.427226543426514\n",
            "For epoch: 0 and batch: 482, the time taken was: 18.687780618667603\n",
            "For epoch: 0 and batch: 483, the time taken was: 18.8301522731781\n",
            "For epoch: 0 and batch: 484, the time taken was: 18.14950203895569\n",
            "For epoch: 0 and batch: 485, the time taken was: 17.7255437374115\n",
            "For epoch: 0 and batch: 486, the time taken was: 17.64648199081421\n",
            "For epoch: 0 and batch: 487, the time taken was: 17.552465438842773\n",
            "For epoch: 0 and batch: 488, the time taken was: 17.383865118026733\n",
            "For epoch: 0 and batch: 489, the time taken was: 17.448029279708862\n",
            "For epoch: 0 and batch: 490, the time taken was: 17.49731945991516\n",
            "For epoch: 0 and batch: 491, the time taken was: 18.59093999862671\n",
            "For epoch: 0 and batch: 492, the time taken was: 17.926419496536255\n",
            "For epoch: 0 and batch: 493, the time taken was: 17.549893856048584\n",
            "For epoch: 0 and batch: 494, the time taken was: 17.552155256271362\n",
            "For epoch: 0 and batch: 495, the time taken was: 17.59014582633972\n",
            "For epoch: 0 and batch: 496, the time taken was: 17.567853927612305\n",
            "For epoch: 0 and batch: 497, the time taken was: 17.673072814941406\n",
            "For epoch: 0 and batch: 498, the time taken was: 17.962498426437378\n",
            "For epoch: 0 and batch: 499, the time taken was: 18.73126244544983\n",
            "For epoch: 0 and batch: 500, the time taken was: 18.581924200057983\n",
            "For epoch: 0 and batch: 501, the time taken was: 18.13047194480896\n",
            "For epoch: 0 and batch: 502, the time taken was: 17.735248804092407\n",
            "For epoch: 0 and batch: 503, the time taken was: 18.873379468917847\n",
            "For epoch: 0 and batch: 504, the time taken was: 18.801727056503296\n",
            "For epoch: 0 and batch: 505, the time taken was: 18.971038579940796\n",
            "For epoch: 0 and batch: 506, the time taken was: 19.64823007583618\n",
            "For epoch: 0 and batch: 507, the time taken was: 18.964829444885254\n",
            "For epoch: 0 and batch: 508, the time taken was: 18.279175758361816\n",
            "For epoch: 0 and batch: 509, the time taken was: 17.153469562530518\n",
            "For epoch: 0 and batch: 510, the time taken was: 17.81600069999695\n",
            "For epoch: 0 and batch: 511, the time taken was: 17.98777461051941\n",
            "For epoch: 0 and batch: 512, the time taken was: 18.15433621406555\n",
            "For epoch: 0 and batch: 513, the time taken was: 18.93421697616577\n",
            "For epoch: 0 and batch: 514, the time taken was: 18.46932864189148\n",
            "For epoch: 0 and batch: 515, the time taken was: 18.019280672073364\n",
            "For epoch: 0 and batch: 516, the time taken was: 17.731300354003906\n",
            "For epoch: 0 and batch: 517, the time taken was: 17.92367911338806\n",
            "For epoch: 0 and batch: 518, the time taken was: 17.505290746688843\n",
            "For epoch: 0 and batch: 519, the time taken was: 17.594715118408203\n",
            "For epoch: 0 and batch: 520, the time taken was: 18.28073215484619\n",
            "For epoch: 0 and batch: 521, the time taken was: 18.21879506111145\n",
            "For epoch: 0 and batch: 522, the time taken was: 17.793744564056396\n",
            "For epoch: 0 and batch: 523, the time taken was: 17.85674238204956\n",
            "For epoch: 0 and batch: 524, the time taken was: 17.493149757385254\n",
            "For epoch: 0 and batch: 525, the time taken was: 17.91874861717224\n",
            "For epoch: 0 and batch: 526, the time taken was: 17.397101640701294\n",
            "For epoch: 0 and batch: 527, the time taken was: 17.145320415496826\n",
            "For epoch: 0 and batch: 528, the time taken was: 17.398529767990112\n",
            "For epoch: 0 and batch: 529, the time taken was: 17.853782176971436\n",
            "For epoch: 0 and batch: 530, the time taken was: 17.919705152511597\n",
            "For epoch: 0 and batch: 531, the time taken was: 18.007829189300537\n",
            "For epoch: 0 and batch: 532, the time taken was: 17.640137910842896\n",
            "For epoch: 0 and batch: 533, the time taken was: 17.499062299728394\n",
            "For epoch: 0 and batch: 534, the time taken was: 17.46520185470581\n",
            "For epoch: 0 and batch: 535, the time taken was: 17.3425030708313\n",
            "For epoch: 0 and batch: 536, the time taken was: 17.162119150161743\n",
            "For epoch: 0 and batch: 537, the time taken was: 17.265413284301758\n",
            "For epoch: 0 and batch: 538, the time taken was: 18.05484127998352\n",
            "For epoch: 0 and batch: 539, the time taken was: 18.201068878173828\n",
            "For epoch: 0 and batch: 540, the time taken was: 17.87872815132141\n",
            "For epoch: 0 and batch: 541, the time taken was: 17.742245197296143\n",
            "For epoch: 0 and batch: 542, the time taken was: 17.398197889328003\n",
            "For epoch: 0 and batch: 543, the time taken was: 17.47902798652649\n",
            "For epoch: 0 and batch: 544, the time taken was: 17.6204833984375\n",
            "For epoch: 0 and batch: 545, the time taken was: 17.546752214431763\n",
            "For epoch: 0 and batch: 546, the time taken was: 17.59236717224121\n",
            "For epoch: 0 and batch: 547, the time taken was: 17.92376136779785\n",
            "For epoch: 0 and batch: 548, the time taken was: 18.255234241485596\n",
            "For epoch: 0 and batch: 549, the time taken was: 17.65599799156189\n",
            "For epoch: 0 and batch: 550, the time taken was: 17.621117115020752\n",
            "For epoch: 0 and batch: 551, the time taken was: 17.725456476211548\n",
            "For epoch: 0 and batch: 552, the time taken was: 17.567070245742798\n",
            "For epoch: 0 and batch: 553, the time taken was: 17.4004807472229\n",
            "For epoch: 0 and batch: 554, the time taken was: 17.25093102455139\n",
            "For epoch: 0 and batch: 555, the time taken was: 18.305659532546997\n",
            "For epoch: 0 and batch: 556, the time taken was: 18.42072629928589\n",
            "For epoch: 0 and batch: 557, the time taken was: 18.088339805603027\n",
            "For epoch: 0 and batch: 558, the time taken was: 17.575008392333984\n",
            "For epoch: 0 and batch: 559, the time taken was: 17.63901662826538\n",
            "For epoch: 0 and batch: 560, the time taken was: 17.436713218688965\n",
            "For epoch: 0 and batch: 561, the time taken was: 17.705735206604004\n",
            "For epoch: 0 and batch: 562, the time taken was: 17.484379529953003\n",
            "For epoch: 0 and batch: 563, the time taken was: 17.45961022377014\n",
            "For epoch: 0 and batch: 564, the time taken was: 17.969249486923218\n",
            "For epoch: 0 and batch: 565, the time taken was: 18.2802152633667\n",
            "For epoch: 0 and batch: 566, the time taken was: 17.747073888778687\n",
            "For epoch: 0 and batch: 567, the time taken was: 17.810433626174927\n",
            "For epoch: 0 and batch: 568, the time taken was: 17.317651987075806\n",
            "For epoch: 0 and batch: 569, the time taken was: 17.616519451141357\n",
            "For epoch: 0 and batch: 570, the time taken was: 17.49499273300171\n",
            "For epoch: 0 and batch: 571, the time taken was: 17.291351556777954\n",
            "For epoch: 0 and batch: 572, the time taken was: 17.691408157348633\n",
            "For epoch: 0 and batch: 573, the time taken was: 18.68343687057495\n",
            "For epoch: 0 and batch: 574, the time taken was: 18.212233781814575\n",
            "For epoch: 0 and batch: 575, the time taken was: 17.57346248626709\n",
            "For epoch: 0 and batch: 576, the time taken was: 17.721558094024658\n",
            "For epoch: 0 and batch: 577, the time taken was: 17.77809739112854\n",
            "For epoch: 0 and batch: 578, the time taken was: 17.46181869506836\n",
            "For epoch: 0 and batch: 579, the time taken was: 17.37010145187378\n",
            "For epoch: 0 and batch: 580, the time taken was: 17.5221905708313\n",
            "For epoch: 0 and batch: 581, the time taken was: 18.24725651741028\n",
            "For epoch: 0 and batch: 582, the time taken was: 18.106489419937134\n",
            "For epoch: 0 and batch: 583, the time taken was: 17.782210111618042\n",
            "For epoch: 0 and batch: 584, the time taken was: 18.078161478042603\n",
            "For epoch: 0 and batch: 585, the time taken was: 17.757363319396973\n",
            "For epoch: 0 and batch: 586, the time taken was: 18.00617241859436\n",
            "For epoch: 0 and batch: 587, the time taken was: 17.523950815200806\n",
            "For epoch: 0 and batch: 588, the time taken was: 18.425793409347534\n",
            "For epoch: 0 and batch: 589, the time taken was: 18.497021675109863\n",
            "For epoch: 0 and batch: 590, the time taken was: 18.045828819274902\n",
            "For epoch: 0 and batch: 591, the time taken was: 17.459694385528564\n",
            "For epoch: 0 and batch: 592, the time taken was: 17.670337438583374\n",
            "For epoch: 0 and batch: 593, the time taken was: 17.609792947769165\n",
            "For epoch: 0 and batch: 594, the time taken was: 17.66681671142578\n",
            "For epoch: 0 and batch: 595, the time taken was: 17.386163234710693\n",
            "For epoch: 0 and batch: 596, the time taken was: 17.66771674156189\n",
            "For epoch: 0 and batch: 597, the time taken was: 18.053670167922974\n",
            "For epoch: 0 and batch: 598, the time taken was: 18.76641011238098\n",
            "For epoch: 0 and batch: 599, the time taken was: 17.687756299972534\n",
            "For epoch: 0 and batch: 600, the time taken was: 17.670870304107666\n",
            "For epoch: 0 and batch: 601, the time taken was: 18.006861209869385\n",
            "For epoch: 0 and batch: 602, the time taken was: 17.435531854629517\n",
            "For epoch: 0 and batch: 603, the time taken was: 17.836740255355835\n",
            "For epoch: 0 and batch: 604, the time taken was: 17.94770050048828\n",
            "For epoch: 0 and batch: 605, the time taken was: 18.945668935775757\n",
            "For epoch: 0 and batch: 606, the time taken was: 18.109914779663086\n",
            "For epoch: 0 and batch: 607, the time taken was: 17.409106016159058\n",
            "For epoch: 0 and batch: 608, the time taken was: 17.762804985046387\n",
            "For epoch: 0 and batch: 609, the time taken was: 17.519143104553223\n",
            "For epoch: 0 and batch: 610, the time taken was: 17.47705888748169\n",
            "For epoch: 0 and batch: 611, the time taken was: 17.57815146446228\n",
            "For epoch: 0 and batch: 612, the time taken was: 17.72105860710144\n",
            "For epoch: 0 and batch: 613, the time taken was: 17.98243737220764\n",
            "For epoch: 0 and batch: 614, the time taken was: 18.266421794891357\n",
            "For epoch: 0 and batch: 615, the time taken was: 17.612633228302002\n",
            "For epoch: 0 and batch: 616, the time taken was: 17.535786628723145\n",
            "For epoch: 0 and batch: 617, the time taken was: 17.643664598464966\n",
            "For epoch: 0 and batch: 618, the time taken was: 17.567556381225586\n",
            "For epoch: 0 and batch: 619, the time taken was: 17.339031219482422\n",
            "For epoch: 0 and batch: 620, the time taken was: 17.3867027759552\n",
            "For epoch: 0 and batch: 621, the time taken was: 17.81457495689392\n",
            "For epoch: 0 and batch: 622, the time taken was: 18.361607551574707\n",
            "For epoch: 0 and batch: 623, the time taken was: 18.182727336883545\n",
            "For epoch: 0 and batch: 624, the time taken was: 17.48149061203003\n",
            "For epoch: 0 and batch: 625, the time taken was: 17.854925632476807\n",
            "For epoch: 0 and batch: 626, the time taken was: 17.62045454978943\n",
            "For epoch: 0 and batch: 627, the time taken was: 17.458588123321533\n",
            "For epoch: 0 and batch: 628, the time taken was: 17.80923366546631\n",
            "For epoch: 0 and batch: 629, the time taken was: 17.38365650177002\n",
            "For epoch: 0 and batch: 630, the time taken was: 18.74426555633545\n",
            "For epoch: 0 and batch: 631, the time taken was: 18.23147964477539\n",
            "For epoch: 0 and batch: 632, the time taken was: 17.42576313018799\n",
            "For epoch: 0 and batch: 633, the time taken was: 17.692150115966797\n",
            "For epoch: 0 and batch: 634, the time taken was: 17.348347187042236\n",
            "For epoch: 0 and batch: 635, the time taken was: 17.7428081035614\n",
            "For epoch: 0 and batch: 636, the time taken was: 17.334760189056396\n",
            "For epoch: 0 and batch: 637, the time taken was: 17.685653924942017\n",
            "For epoch: 0 and batch: 638, the time taken was: 17.962167978286743\n",
            "For epoch: 0 and batch: 639, the time taken was: 18.22579073905945\n",
            "For epoch: 0 and batch: 640, the time taken was: 17.86024570465088\n",
            "For epoch: 0 and batch: 641, the time taken was: 17.809096097946167\n",
            "For epoch: 0 and batch: 642, the time taken was: 17.399261951446533\n",
            "For epoch: 0 and batch: 643, the time taken was: 17.640089750289917\n",
            "For epoch: 0 and batch: 644, the time taken was: 17.387805700302124\n",
            "For epoch: 0 and batch: 645, the time taken was: 17.50816011428833\n",
            "For epoch: 0 and batch: 646, the time taken was: 18.665400743484497\n",
            "For epoch: 0 and batch: 647, the time taken was: 18.410913228988647\n",
            "For epoch: 0 and batch: 648, the time taken was: 18.202259302139282\n",
            "For epoch: 0 and batch: 649, the time taken was: 17.54098129272461\n",
            "For epoch: 0 and batch: 650, the time taken was: 17.858938455581665\n",
            "For epoch: 0 and batch: 651, the time taken was: 17.435665369033813\n",
            "For epoch: 0 and batch: 652, the time taken was: 17.420372009277344\n",
            "For epoch: 0 and batch: 653, the time taken was: 17.53307271003723\n",
            "For epoch: 0 and batch: 654, the time taken was: 17.647482872009277\n",
            "For epoch: 0 and batch: 655, the time taken was: 17.454887628555298\n",
            "For epoch: 0 and batch: 656, the time taken was: 18.02489948272705\n",
            "For epoch: 0 and batch: 657, the time taken was: 17.48504614830017\n",
            "For epoch: 0 and batch: 658, the time taken was: 17.578723430633545\n",
            "For epoch: 0 and batch: 659, the time taken was: 17.531773328781128\n",
            "For epoch: 0 and batch: 660, the time taken was: 17.543590784072876\n",
            "For epoch: 0 and batch: 661, the time taken was: 17.227668523788452\n",
            "For epoch: 0 and batch: 662, the time taken was: 17.125920295715332\n",
            "For epoch: 0 and batch: 663, the time taken was: 17.390422344207764\n",
            "For epoch: 0 and batch: 664, the time taken was: 17.8391432762146\n",
            "For epoch: 0 and batch: 665, the time taken was: 18.106420755386353\n",
            "For epoch: 0 and batch: 666, the time taken was: 17.705965995788574\n",
            "For epoch: 0 and batch: 667, the time taken was: 17.568291902542114\n",
            "For epoch: 0 and batch: 668, the time taken was: 17.47997736930847\n",
            "For epoch: 0 and batch: 669, the time taken was: 17.573261976242065\n",
            "For epoch: 0 and batch: 670, the time taken was: 17.82002878189087\n",
            "For epoch: 0 and batch: 671, the time taken was: 17.294334650039673\n",
            "For epoch: 0 and batch: 672, the time taken was: 17.762011766433716\n",
            "For epoch: 0 and batch: 673, the time taken was: 18.03571629524231\n",
            "For epoch: 0 and batch: 674, the time taken was: 18.17551279067993\n",
            "For epoch: 0 and batch: 675, the time taken was: 17.542266130447388\n",
            "For epoch: 0 and batch: 676, the time taken was: 17.557114601135254\n",
            "For epoch: 0 and batch: 677, the time taken was: 17.44698667526245\n",
            "For epoch: 0 and batch: 678, the time taken was: 17.302492380142212\n",
            "For epoch: 0 and batch: 679, the time taken was: 17.693454265594482\n",
            "For epoch: 0 and batch: 680, the time taken was: 17.419811964035034\n",
            "For epoch: 0 and batch: 681, the time taken was: 17.865647077560425\n",
            "For epoch: 0 and batch: 682, the time taken was: 17.992770195007324\n",
            "For epoch: 0 and batch: 683, the time taken was: 17.863932371139526\n",
            "For epoch: 0 and batch: 684, the time taken was: 17.575058460235596\n",
            "For epoch: 0 and batch: 685, the time taken was: 17.48865532875061\n",
            "For epoch: 0 and batch: 686, the time taken was: 17.715553522109985\n",
            "For epoch: 0 and batch: 687, the time taken was: 17.49466300010681\n",
            "For epoch: 0 and batch: 688, the time taken was: 17.912033557891846\n",
            "For epoch: 0 and batch: 689, the time taken was: 17.77601718902588\n",
            "For epoch: 0 and batch: 690, the time taken was: 17.947502613067627\n",
            "For epoch: 0 and batch: 691, the time taken was: 17.89229655265808\n",
            "For epoch: 0 and batch: 692, the time taken was: 17.844276428222656\n",
            "For epoch: 0 and batch: 693, the time taken was: 17.557818174362183\n",
            "For epoch: 0 and batch: 694, the time taken was: 17.370482921600342\n",
            "For epoch: 0 and batch: 695, the time taken was: 17.465308666229248\n",
            "For epoch: 0 and batch: 696, the time taken was: 17.449558973312378\n",
            "For epoch: 0 and batch: 697, the time taken was: 17.30586314201355\n",
            "For epoch: 0 and batch: 698, the time taken was: 17.31669783592224\n",
            "For epoch: 0 and batch: 699, the time taken was: 17.88087224960327\n",
            "For epoch: 0 and batch: 700, the time taken was: 18.050986528396606\n",
            "For epoch: 0 and batch: 701, the time taken was: 17.606799125671387\n",
            "For epoch: 0 and batch: 702, the time taken was: 17.397514581680298\n",
            "For epoch: 0 and batch: 703, the time taken was: 17.44335627555847\n",
            "For epoch: 0 and batch: 704, the time taken was: 17.71850872039795\n",
            "For epoch: 0 and batch: 705, the time taken was: 17.605584383010864\n",
            "For epoch: 0 and batch: 706, the time taken was: 17.58634114265442\n",
            "For epoch: 0 and batch: 707, the time taken was: 18.818204879760742\n",
            "For epoch: 0 and batch: 708, the time taken was: 18.36240267753601\n",
            "For epoch: 0 and batch: 709, the time taken was: 18.257676601409912\n",
            "For epoch: 0 and batch: 710, the time taken was: 17.998128414154053\n",
            "For epoch: 0 and batch: 711, the time taken was: 17.609467267990112\n",
            "For epoch: 0 and batch: 712, the time taken was: 17.74836254119873\n",
            "For epoch: 0 and batch: 713, the time taken was: 17.698275804519653\n",
            "For epoch: 0 and batch: 714, the time taken was: 18.164724111557007\n",
            "For epoch: 0 and batch: 715, the time taken was: 18.513518810272217\n",
            "For epoch: 0 and batch: 716, the time taken was: 18.11458683013916\n",
            "For epoch: 0 and batch: 717, the time taken was: 17.743396759033203\n",
            "For epoch: 0 and batch: 718, the time taken was: 18.0703387260437\n",
            "For epoch: 0 and batch: 719, the time taken was: 17.878175973892212\n",
            "For epoch: 0 and batch: 720, the time taken was: 18.230652570724487\n",
            "For epoch: 0 and batch: 721, the time taken was: 17.876352787017822\n",
            "For epoch: 0 and batch: 722, the time taken was: 18.867356061935425\n",
            "For epoch: 0 and batch: 723, the time taken was: 18.16064214706421\n",
            "For epoch: 0 and batch: 724, the time taken was: 17.86074161529541\n",
            "For epoch: 0 and batch: 725, the time taken was: 18.229645490646362\n",
            "For epoch: 0 and batch: 726, the time taken was: 17.616024494171143\n",
            "For epoch: 0 and batch: 727, the time taken was: 17.5035662651062\n",
            "For epoch: 0 and batch: 728, the time taken was: 17.691707134246826\n",
            "For epoch: 0 and batch: 729, the time taken was: 18.261587619781494\n",
            "For epoch: 0 and batch: 730, the time taken was: 18.990333080291748\n",
            "For epoch: 0 and batch: 731, the time taken was: 18.050190448760986\n",
            "For epoch: 0 and batch: 732, the time taken was: 17.68906283378601\n",
            "For epoch: 0 and batch: 733, the time taken was: 17.639665842056274\n",
            "For epoch: 0 and batch: 734, the time taken was: 17.671501636505127\n",
            "For epoch: 0 and batch: 735, the time taken was: 17.52953815460205\n",
            "For epoch: 0 and batch: 736, the time taken was: 17.524798154830933\n",
            "For epoch: 0 and batch: 737, the time taken was: 18.155933141708374\n",
            "For epoch: 0 and batch: 738, the time taken was: 18.14755129814148\n",
            "For epoch: 0 and batch: 739, the time taken was: 17.73534917831421\n",
            "For epoch: 0 and batch: 740, the time taken was: 17.51185154914856\n",
            "For epoch: 0 and batch: 741, the time taken was: 17.843504905700684\n",
            "For epoch: 0 and batch: 742, the time taken was: 17.521673440933228\n",
            "For epoch: 0 and batch: 743, the time taken was: 17.37589192390442\n",
            "For epoch: 0 and batch: 744, the time taken was: 17.437554121017456\n",
            "For epoch: 0 and batch: 745, the time taken was: 17.369189977645874\n",
            "For epoch: 0 and batch: 746, the time taken was: 18.088162660598755\n",
            "For epoch: 0 and batch: 747, the time taken was: 17.945029973983765\n",
            "For epoch: 0 and batch: 748, the time taken was: 18.09291648864746\n",
            "For epoch: 0 and batch: 749, the time taken was: 17.496097087860107\n",
            "For epoch: 0 and batch: 750, the time taken was: 17.999050617218018\n",
            "For epoch: 0 and batch: 751, the time taken was: 17.496975660324097\n",
            "For epoch: 0 and batch: 752, the time taken was: 18.02546238899231\n",
            "For epoch: 0 and batch: 753, the time taken was: 17.751208305358887\n",
            "For epoch: 0 and batch: 754, the time taken was: 18.497250080108643\n",
            "For epoch: 0 and batch: 755, the time taken was: 18.16166877746582\n",
            "For epoch: 0 and batch: 756, the time taken was: 17.739192485809326\n",
            "For epoch: 0 and batch: 757, the time taken was: 17.58936071395874\n",
            "For epoch: 0 and batch: 758, the time taken was: 17.98493480682373\n",
            "For epoch: 0 and batch: 759, the time taken was: 17.52841353416443\n",
            "For epoch: 0 and batch: 760, the time taken was: 17.541351795196533\n",
            "For epoch: 0 and batch: 761, the time taken was: 17.732460260391235\n",
            "For epoch: 0 and batch: 762, the time taken was: 18.305057287216187\n",
            "For epoch: 0 and batch: 763, the time taken was: 18.92980933189392\n",
            "For epoch: 0 and batch: 764, the time taken was: 17.734581232070923\n",
            "For epoch: 0 and batch: 765, the time taken was: 18.0035617351532\n",
            "For epoch: 0 and batch: 766, the time taken was: 17.656845808029175\n",
            "For epoch: 0 and batch: 767, the time taken was: 17.65496826171875\n",
            "For epoch: 0 and batch: 768, the time taken was: 17.72121500968933\n",
            "For epoch: 0 and batch: 769, the time taken was: 17.541792154312134\n",
            "For epoch: 0 and batch: 770, the time taken was: 18.316633224487305\n",
            "For epoch: 0 and batch: 771, the time taken was: 18.161288261413574\n",
            "For epoch: 0 and batch: 772, the time taken was: 17.67927360534668\n",
            "For epoch: 0 and batch: 773, the time taken was: 17.755996465682983\n",
            "For epoch: 0 and batch: 774, the time taken was: 17.845275163650513\n",
            "For epoch: 0 and batch: 775, the time taken was: 17.493577241897583\n",
            "For epoch: 0 and batch: 776, the time taken was: 17.47861385345459\n",
            "For epoch: 0 and batch: 777, the time taken was: 17.4366135597229\n",
            "For epoch: 0 and batch: 778, the time taken was: 17.686063766479492\n",
            "For epoch: 0 and batch: 779, the time taken was: 17.81273627281189\n",
            "For epoch: 0 and batch: 780, the time taken was: 18.01582384109497\n",
            "For epoch: 0 and batch: 781, the time taken was: 17.550846099853516\n",
            "For epoch: 0 and batch: 782, the time taken was: 17.771520137786865\n",
            "For epoch: 0 and batch: 783, the time taken was: 17.677937269210815\n",
            "For epoch: 0 and batch: 784, the time taken was: 17.9008469581604\n",
            "For epoch: 0 and batch: 785, the time taken was: 17.571396112442017\n",
            "For epoch: 0 and batch: 786, the time taken was: 17.468183279037476\n",
            "For epoch: 0 and batch: 787, the time taken was: 18.459701776504517\n",
            "For epoch: 0 and batch: 788, the time taken was: 18.333184957504272\n",
            "For epoch: 0 and batch: 789, the time taken was: 18.19153928756714\n",
            "For epoch: 0 and batch: 790, the time taken was: 17.898924350738525\n",
            "For epoch: 0 and batch: 791, the time taken was: 17.59872341156006\n",
            "For epoch: 0 and batch: 792, the time taken was: 17.72024631500244\n",
            "For epoch: 0 and batch: 793, the time taken was: 17.492681980133057\n",
            "For epoch: 0 and batch: 794, the time taken was: 17.73759913444519\n",
            "For epoch: 0 and batch: 795, the time taken was: 18.694947957992554\n",
            "For epoch: 0 and batch: 796, the time taken was: 18.3624165058136\n",
            "For epoch: 0 and batch: 797, the time taken was: 17.68862748146057\n",
            "For epoch: 0 and batch: 798, the time taken was: 17.94559645652771\n",
            "For epoch: 0 and batch: 799, the time taken was: 17.949235200881958\n",
            "For epoch: 0 and batch: 800, the time taken was: 17.816526651382446\n",
            "For epoch: 0 and batch: 801, the time taken was: 17.240251302719116\n",
            "For epoch: 0 and batch: 802, the time taken was: 17.722281455993652\n",
            "For epoch: 0 and batch: 803, the time taken was: 18.286741733551025\n",
            "For epoch: 0 and batch: 804, the time taken was: 18.478023052215576\n",
            "For epoch: 0 and batch: 805, the time taken was: 18.752506256103516\n",
            "For epoch: 0 and batch: 806, the time taken was: 17.701212406158447\n",
            "For epoch: 0 and batch: 807, the time taken was: 18.00358510017395\n",
            "For epoch: 0 and batch: 808, the time taken was: 17.77962064743042\n",
            "For epoch: 0 and batch: 809, the time taken was: 17.602970838546753\n",
            "For epoch: 0 and batch: 810, the time taken was: 18.27459478378296\n",
            "For epoch: 0 and batch: 811, the time taken was: 18.55247974395752\n",
            "For epoch: 0 and batch: 812, the time taken was: 18.061801433563232\n",
            "For epoch: 0 and batch: 813, the time taken was: 17.845658779144287\n",
            "For epoch: 0 and batch: 814, the time taken was: 18.090150356292725\n",
            "For epoch: 0 and batch: 815, the time taken was: 18.213013410568237\n",
            "For epoch: 0 and batch: 816, the time taken was: 17.642781734466553\n",
            "For epoch: 0 and batch: 817, the time taken was: 18.30061960220337\n",
            "For epoch: 0 and batch: 818, the time taken was: 18.9974262714386\n",
            "For epoch: 0 and batch: 819, the time taken was: 18.2268648147583\n",
            "For epoch: 0 and batch: 820, the time taken was: 17.310170650482178\n",
            "For epoch: 0 and batch: 821, the time taken was: 17.791619300842285\n",
            "For epoch: 0 and batch: 822, the time taken was: 17.68662428855896\n",
            "For epoch: 0 and batch: 823, the time taken was: 17.768205642700195\n",
            "For epoch: 0 and batch: 824, the time taken was: 17.912739753723145\n",
            "For epoch: 0 and batch: 825, the time taken was: 18.742279767990112\n",
            "For epoch: 0 and batch: 826, the time taken was: 18.665221452713013\n",
            "For epoch: 0 and batch: 827, the time taken was: 17.63069725036621\n",
            "For epoch: 0 and batch: 828, the time taken was: 17.528423309326172\n",
            "For epoch: 0 and batch: 829, the time taken was: 17.85240364074707\n",
            "For epoch: 0 and batch: 830, the time taken was: 17.4706711769104\n",
            "For epoch: 0 and batch: 831, the time taken was: 17.55959677696228\n",
            "For epoch: 0 and batch: 832, the time taken was: 17.463018894195557\n",
            "Model successfully trained\n"
          ]
        }
      ],
      "source": [
        "# Load the pre-trained BERT model and tokenizer\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\n",
        "\n",
        "# Adding a dropout layer and a fully connected layer on top of the BERT model for classification i.e. the head\n",
        "model.classifier = torch.nn.Sequential(\n",
        "    torch.nn.Dropout(0.2),\n",
        "    torch.nn.Linear(in_features=model.config.hidden_size, out_features=2)\n",
        ")\n",
        "\n",
        "# Define the optimizer and loss function\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=2e-5)\n",
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "# Train the model on the training data\n",
        "for epoch in range(1):\n",
        "    count=0\n",
        "    for batch in train_dataloader:\n",
        "        previous_time = time.time()\n",
        "        input_ids, attention_mask, labels = batch\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
        "        loss = outputs.loss\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        current_time = time.time()\n",
        "        print(f\"For epoch: {epoch} and batch: {count}, the time taken was: {current_time-previous_time}\")\n",
        "        count+=1\n",
        "print(\"Model successfully trained\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X9Wu2r3sFW4o"
      },
      "outputs": [],
      "source": [
        "# Save the model state dictionary\n",
        "torch.save(model.state_dict(), '/content/drive/MyDrive/COMP_551/A3/aclImdb/model.pth')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1235840e2ed447929e9b1fede396525a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fdc0b659cc734572bf383114b687beff",
              "IPY_MODEL_97331fa7721445e695708015e5f54ae8",
              "IPY_MODEL_f5bbe87411cd4ac4a84d24e757cb08f0"
            ],
            "layout": "IPY_MODEL_fc8a95296f4943bd8d4e3baaf1db8792"
          }
        },
        "fdc0b659cc734572bf383114b687beff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5d1583ac44de4024bc64d90329300a03",
            "placeholder": "​",
            "style": "IPY_MODEL_5ddcf8fa3ca24fcb84e4156aa303de52",
            "value": "Downloading (…)solve/main/vocab.txt: 100%"
          }
        },
        "97331fa7721445e695708015e5f54ae8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f079c4d9ffcf40e687ed78a71ea45b17",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1c0ffa5673d74d618f13040b5c860da0",
            "value": 231508
          }
        },
        "f5bbe87411cd4ac4a84d24e757cb08f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f165db08018c484298b9349c1b4bc4b8",
            "placeholder": "​",
            "style": "IPY_MODEL_e164a45641d044ebbe022027804faded",
            "value": " 232k/232k [00:00&lt;00:00, 4.01MB/s]"
          }
        },
        "fc8a95296f4943bd8d4e3baaf1db8792": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5d1583ac44de4024bc64d90329300a03": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5ddcf8fa3ca24fcb84e4156aa303de52": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f079c4d9ffcf40e687ed78a71ea45b17": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1c0ffa5673d74d618f13040b5c860da0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f165db08018c484298b9349c1b4bc4b8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e164a45641d044ebbe022027804faded": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "72753eedda8f42b78275d30e92c26493": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_63b23e799ab64fb0824f5404a6f207f6",
              "IPY_MODEL_f0dc9ffebb394b099b0dfe8733126e18",
              "IPY_MODEL_5cea755b34a3416d8e9d4a2941152e2d"
            ],
            "layout": "IPY_MODEL_0bf9a11aa8ca4482809ffe7306514a6e"
          }
        },
        "63b23e799ab64fb0824f5404a6f207f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dcdbf913031440c39a1925e60e6571da",
            "placeholder": "​",
            "style": "IPY_MODEL_1c643513f5af443ea0b5bc14cc71198b",
            "value": "Downloading (…)okenizer_config.json: 100%"
          }
        },
        "f0dc9ffebb394b099b0dfe8733126e18": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d6a6a9098ac145faa6c142fc89a75b15",
            "max": 28,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_76f2316ac0b54d27afc076599ccf4ac9",
            "value": 28
          }
        },
        "5cea755b34a3416d8e9d4a2941152e2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_31d798f77b6f4fcebb241fd4809ecfcd",
            "placeholder": "​",
            "style": "IPY_MODEL_a6d54c174a2b42d99ec8839b62de5e71",
            "value": " 28.0/28.0 [00:00&lt;00:00, 731B/s]"
          }
        },
        "0bf9a11aa8ca4482809ffe7306514a6e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dcdbf913031440c39a1925e60e6571da": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1c643513f5af443ea0b5bc14cc71198b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d6a6a9098ac145faa6c142fc89a75b15": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "76f2316ac0b54d27afc076599ccf4ac9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "31d798f77b6f4fcebb241fd4809ecfcd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a6d54c174a2b42d99ec8839b62de5e71": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "879e098c214b4981b3bd7285939c9f24": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bcd71e61ba114eb2a37dd78b66cf660f",
              "IPY_MODEL_6e6517ff533c4611afc72af48c17d14f",
              "IPY_MODEL_74d186a02f0f43fab3732fb107441e84"
            ],
            "layout": "IPY_MODEL_5626b8aba29c49dab33ff1b8b95c1658"
          }
        },
        "bcd71e61ba114eb2a37dd78b66cf660f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4dfb8b27da27462a884f558c85b6e088",
            "placeholder": "​",
            "style": "IPY_MODEL_5964ab981efa4a1ebc1297959affb267",
            "value": "Downloading (…)lve/main/config.json: 100%"
          }
        },
        "6e6517ff533c4611afc72af48c17d14f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ad008230bee74380b20c9201c2d856b9",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8ead029340054d2ebb13b5ff4c7c56dc",
            "value": 570
          }
        },
        "74d186a02f0f43fab3732fb107441e84": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_edf3da7571ce43ab8f2901230c6b0f5f",
            "placeholder": "​",
            "style": "IPY_MODEL_50fdc97b7f4b4913b5553675a706aaa6",
            "value": " 570/570 [00:00&lt;00:00, 20.1kB/s]"
          }
        },
        "5626b8aba29c49dab33ff1b8b95c1658": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4dfb8b27da27462a884f558c85b6e088": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5964ab981efa4a1ebc1297959affb267": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ad008230bee74380b20c9201c2d856b9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8ead029340054d2ebb13b5ff4c7c56dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "edf3da7571ce43ab8f2901230c6b0f5f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "50fdc97b7f4b4913b5553675a706aaa6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e8afffa495c349f0a6c35a0949c964c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a8fbb85dd0bc4296be46c50dc4d233fa",
              "IPY_MODEL_fd9948e393d746dca1308189ab653d26",
              "IPY_MODEL_ca16270ceeff4a80a66cf82ef9f957ae"
            ],
            "layout": "IPY_MODEL_1c7a59e699fb4f7698f4dab679716165"
          }
        },
        "a8fbb85dd0bc4296be46c50dc4d233fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5f4b7be7bfce4a8c9b5e200ddc6bce53",
            "placeholder": "​",
            "style": "IPY_MODEL_3f4015d49aa24450a759d2f76651f384",
            "value": "Downloading pytorch_model.bin: 100%"
          }
        },
        "fd9948e393d746dca1308189ab653d26": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_86e34cc0cdba4275816f247d3fa71506",
            "max": 440473133,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_29b58ffaa04a405e9951e26073c88453",
            "value": 440473133
          }
        },
        "ca16270ceeff4a80a66cf82ef9f957ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_798192db36a049ac8cc3066103d6e27f",
            "placeholder": "​",
            "style": "IPY_MODEL_04b5cee4f8944b5c892cd4ee4524b8c0",
            "value": " 440M/440M [00:02&lt;00:00, 147MB/s]"
          }
        },
        "1c7a59e699fb4f7698f4dab679716165": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5f4b7be7bfce4a8c9b5e200ddc6bce53": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3f4015d49aa24450a759d2f76651f384": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "86e34cc0cdba4275816f247d3fa71506": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "29b58ffaa04a405e9951e26073c88453": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "798192db36a049ac8cc3066103d6e27f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "04b5cee4f8944b5c892cd4ee4524b8c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}