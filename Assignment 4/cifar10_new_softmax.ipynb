{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tuVZ0x0qAxY9",
        "outputId": "0104a8ce-75b9-4068-87a2-d3c727ac0d48"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170498071/170498071 [==============================] - 4s 0us/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "352/352 [==============================] - 334s 940ms/step - loss: 1.8563 - accuracy: 0.4045 - val_loss: 2.8683 - val_accuracy: 0.1808\n",
            "Epoch 2/30\n",
            "352/352 [==============================] - 334s 950ms/step - loss: 1.2493 - accuracy: 0.5557 - val_loss: 1.0913 - val_accuracy: 0.6072\n",
            "Epoch 3/30\n",
            "352/352 [==============================] - 336s 955ms/step - loss: 1.0654 - accuracy: 0.6265 - val_loss: 0.9278 - val_accuracy: 0.6706\n",
            "Epoch 4/30\n",
            "352/352 [==============================] - 340s 965ms/step - loss: 0.9473 - accuracy: 0.6694 - val_loss: 0.8391 - val_accuracy: 0.7216\n",
            "Epoch 5/30\n",
            "352/352 [==============================] - 340s 967ms/step - loss: 0.8577 - accuracy: 0.7042 - val_loss: 0.8725 - val_accuracy: 0.7044\n",
            "Epoch 6/30\n",
            "352/352 [==============================] - 341s 970ms/step - loss: 0.7883 - accuracy: 0.7247 - val_loss: 0.7255 - val_accuracy: 0.7542\n",
            "Epoch 7/30\n",
            "352/352 [==============================] - 337s 957ms/step - loss: 0.7231 - accuracy: 0.7511 - val_loss: 0.6941 - val_accuracy: 0.7774\n",
            "Epoch 8/30\n",
            "352/352 [==============================] - 337s 959ms/step - loss: 0.6649 - accuracy: 0.7674 - val_loss: 0.7618 - val_accuracy: 0.7476\n",
            "Epoch 9/30\n",
            "352/352 [==============================] - 336s 955ms/step - loss: 0.6167 - accuracy: 0.7887 - val_loss: 0.7142 - val_accuracy: 0.7614\n",
            "Epoch 10/30\n",
            "352/352 [==============================] - 337s 957ms/step - loss: 0.5708 - accuracy: 0.8005 - val_loss: 0.6328 - val_accuracy: 0.7910\n",
            "Epoch 11/30\n",
            "352/352 [==============================] - 337s 957ms/step - loss: 0.5290 - accuracy: 0.8142 - val_loss: 0.6447 - val_accuracy: 0.7946\n",
            "Epoch 12/30\n",
            "352/352 [==============================] - 336s 954ms/step - loss: 0.4936 - accuracy: 0.8297 - val_loss: 0.6505 - val_accuracy: 0.7918\n",
            "Epoch 13/30\n",
            "352/352 [==============================] - 337s 957ms/step - loss: 0.4546 - accuracy: 0.8414 - val_loss: 0.6341 - val_accuracy: 0.8024\n",
            "Epoch 14/30\n",
            "352/352 [==============================] - 336s 956ms/step - loss: 0.4283 - accuracy: 0.8521 - val_loss: 0.6206 - val_accuracy: 0.8132\n",
            "Epoch 15/30\n",
            "352/352 [==============================] - 334s 950ms/step - loss: 0.4038 - accuracy: 0.8585 - val_loss: 0.6257 - val_accuracy: 0.8046\n",
            "Epoch 16/30\n",
            "352/352 [==============================] - 335s 953ms/step - loss: 0.3767 - accuracy: 0.8688 - val_loss: 0.6744 - val_accuracy: 0.7992\n",
            "Epoch 17/30\n",
            "352/352 [==============================] - 335s 952ms/step - loss: 0.3559 - accuracy: 0.8742 - val_loss: 0.7106 - val_accuracy: 0.7936\n",
            "Epoch 18/30\n",
            "352/352 [==============================] - 338s 958ms/step - loss: 0.3423 - accuracy: 0.8812 - val_loss: 0.6214 - val_accuracy: 0.8190\n",
            "Epoch 19/30\n",
            "352/352 [==============================] - 336s 953ms/step - loss: 0.3281 - accuracy: 0.8878 - val_loss: 0.6237 - val_accuracy: 0.8196\n",
            "Epoch 20/30\n",
            "352/352 [==============================] - 336s 955ms/step - loss: 0.3048 - accuracy: 0.8953 - val_loss: 0.7277 - val_accuracy: 0.8010\n",
            "Epoch 21/30\n",
            "352/352 [==============================] - 336s 955ms/step - loss: 0.3010 - accuracy: 0.8963 - val_loss: 0.7072 - val_accuracy: 0.8074\n",
            "Epoch 22/30\n",
            "352/352 [==============================] - 336s 955ms/step - loss: 0.2712 - accuracy: 0.9065 - val_loss: 0.5972 - val_accuracy: 0.8262\n",
            "Epoch 23/30\n",
            "352/352 [==============================] - 336s 954ms/step - loss: 0.2702 - accuracy: 0.9086 - val_loss: 0.6745 - val_accuracy: 0.8152\n",
            "Epoch 24/30\n",
            "352/352 [==============================] - 337s 957ms/step - loss: 0.2580 - accuracy: 0.9107 - val_loss: 0.6342 - val_accuracy: 0.8260\n",
            "Epoch 25/30\n",
            "352/352 [==============================] - 337s 957ms/step - loss: 0.2438 - accuracy: 0.9163 - val_loss: 0.7239 - val_accuracy: 0.8146\n",
            "Epoch 26/30\n",
            "352/352 [==============================] - 338s 960ms/step - loss: 0.2396 - accuracy: 0.9180 - val_loss: 0.7114 - val_accuracy: 0.8170\n",
            "Epoch 27/30\n",
            "352/352 [==============================] - 336s 955ms/step - loss: 0.2259 - accuracy: 0.9225 - val_loss: 0.6824 - val_accuracy: 0.8258\n",
            "Epoch 28/30\n",
            "352/352 [==============================] - 337s 958ms/step - loss: 0.2229 - accuracy: 0.9232 - val_loss: 0.7863 - val_accuracy: 0.8134\n",
            "Epoch 29/30\n",
            "352/352 [==============================] - 336s 954ms/step - loss: 0.2169 - accuracy: 0.9258 - val_loss: 0.6447 - val_accuracy: 0.8260\n",
            "Epoch 30/30\n",
            "352/352 [==============================] - 336s 955ms/step - loss: 0.2125 - accuracy: 0.9271 - val_loss: 0.7061 - val_accuracy: 0.8308\n",
            "313/313 [==============================] - 19s 59ms/step - loss: 0.7336 - accuracy: 0.8126\n",
            "Test Accuracy: 0.8126000165939331\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, BatchNormalization\n",
        "from tensorflow.keras.losses import CategoricalCrossentropy\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "\n",
        "# Load the CIFAR-10 dataset\n",
        "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
        "\n",
        "# Preprocess the data\n",
        "X_train = X_train.astype('float32') / 255.\n",
        "X_test = X_test.astype('float32') / 255.\n",
        "\n",
        "# Convert the labels to one-hot encoding\n",
        "y_train = tf.keras.utils.to_categorical(y_train, num_classes=10)\n",
        "y_test = tf.keras.utils.to_categorical(y_test, num_classes=10)\n",
        "\n",
        "\n",
        "# Define the model architecture\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', padding='same', input_shape=(32, 32, 3)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(128, kernel_size=(3, 3), activation='relu', padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "# Compile the model with cross-entropy loss and Adam optimizer\n",
        "model.compile(loss=CategoricalCrossentropy(), optimizer=Adam(lr=0.0001), metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, batch_size=128, epochs=30, validation_split=0.1)\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
        "\n",
        "# Print the test accuracy score\n",
        "print(\"Test Accuracy:\", test_accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yzm5_Jm2LQny"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}